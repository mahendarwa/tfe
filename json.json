Key Highlights from the Discussion:
	1. AWS S3 Cleanup Process in ARIES Common
		○ A script in ARIES Common AWS Ops - S3 Ops - Versions is used to clean up old S3 objects efficiently.
		○ Supports bucket selection, prefix filtering, time delta, and version-based cleanup (previous, latest, all).
	2. Planned S3 Cleanup Execution
		○ Cleanup was done in Dev, next steps include QA and later Prod.
		○ Users need to be notified before cleanup to confirm data requirements.
	3. Challenges in S3 Cleanup
		○ Some configuration files and test data (e.g., PI tests, Snowflake config) should not be deleted.
		○ Users are still writing output where they shouldn’t, leading to unnecessary data retention.
	4. S3 Versioning & Automation
		○ Objects often have multiple versions, making manual deletion difficult.
		○ The script automates cleanup by retrieving version IDs and deleting outdated objects.
		○ A preview mode allows users to check what will be deleted before committing the action.
	5. Logging & Access Restrictions
		○ Cleanup operations generate detailed logs stored under apps → ARIES → AWS Ops → S3 Ops → Versions → Logs.
	6. Decommissioning Aries Common & Tomcat HTTPD
		○ Aries Common was an infrastructure API but is no longer needed.
		○ Aries Common Tomcat HTTPD instance should be decommissioned, as it only supports Snowflake config updates.
		○ Future credential storage should move from S3 to the local file system.
	7. Next Steps in Cleanup & Transition
		○ Confirm with QRM team whether QA cleanup should proceed.
		○ Execute cleanup in QA and Prod after approvals.
		○ Fix access issues for log files and ensure logs are correctly stored.
Decommission Aries Common Tomcat HTTPD and shift S3-stored credentials to local config storage.
